{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DnaA boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DnaA protein are binded to regions called dnaA boxes in the region knowed as ori, where the replication processes begin. Finding ori is one of the key tasks to understand how cells replicate. First lets search for frequent characters in ori, because some nucleotide string appear surprisingly often in small regions of genome. \n",
    "We will start with a bacterium called Vibrio cholerae, and then design a computational approach for finding ori in other bacteria genomes.\n",
    "\n",
    "Here is the nucleotide sequence appearing in the ori of Vibrio cholerae:\n",
    "\n",
    "![ORI vibrio](data/Screenshot_20200712_003201.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-mer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One possible approach is design a \"sliding window\" that will go through the text checking where each substring of the input text matches with the pattern that we are looking for\n",
    "\n",
    "K-mer pseudocode:\n",
    "\n",
    "![Pseudocode k-mer](data/k-mer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the python language, let's implement the pseudocode.\n",
    "\n",
    "ps: Obviously, in python language, there is a lot of ways of doing so, many of them much more efficient and simple, but lets keep the code more like the pseudocode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PatternCount(text, pattern):\n",
    "\tcount = 0\n",
    "\n",
    "\tfor i in range(len(text) - len(pattern)):\n",
    "\t\tif text[i: i + len(pattern)] == pattern:\n",
    "\t\t\tcount += 1\n",
    "\treturn count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13125\n"
     ]
    }
   ],
   "source": [
    "#Example\n",
    "text = open(\"data/ori_vibrio.txt\", \"r\")\n",
    "texto = text.read()\n",
    "count = PatternCount(texto, 'CCG')\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequent word\n",
    "We say that a pattern is a most frequent k-mer in the input text if it maximizes Count(Text, Pattern) among all k-mers. For instance, ACTAT is a most frequent 5-mer of ACAACTATGCATACTATCGGGAACTATCCT.\n",
    "\n",
    "One algorithm for finding the most frequent k-mers in a string checks all k-mers appearing in this input string, then computes how many times each k-mer appears in the string. To implement this FrequentWords algorithm, lets make an array Count, where Count(i) stores Count(Text, Pattern) for Pattern = Text(i, k).\n",
    "\n",
    "Frequentwords pseudocode:\n",
    "![Pseudocode frequentwords](data/frequentwords.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FrequentWordsProblem(text, k):\n",
    "\tfrequentPatterns = []\n",
    "\tcount = np.zeros(shape=(len(text) - k + 1))\n",
    "\n",
    "\tfor i in range(len(text) - k):\n",
    "\t\tpattern = text[i: i + k]\n",
    "\t\tcount[i] = PatternCount(text, pattern)\n",
    "\n",
    "\tmax_count_indicies = np.where(count == np.max(count))\n",
    "\t\n",
    "\tfor i in max_count_indicies[0]:\n",
    "\t\tif text[i:i+k] not in frequentPatterns:\n",
    "\t\t\tfrequentPatterns.append(text[i:i+k])\n",
    "\treturn frequentPatterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GCAT', 'CATG']\n"
     ]
    }
   ],
   "source": [
    "frequent = FrequentWordsProblem('ACGTTGCATGTCGCATGATGCATGAGAGCT', 4)\n",
    "print(frequent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FrequentWords finds most frequent k-mers, but is not very efficient. Each call to PatternCount function checks whether the k-mer pattern appears in all positions of the text. Since each k-mer requires |Text| − k + 1 such checks, each one requiring as many as k comparisons, the overall number of steps of PatternCount is (|Text| − k + 1) · k. Furthermore, FrequentWords must call PatternCount |Text| − k + 1 times (once for each k-mer of Text), so that its overall number of steps is (|Text| − k + 1) · (|Text| − k + 1) · k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching for hidden messages in multiple genomes\n",
    "\n",
    "Not all bacteria has the same DnaA boxes. Let's take a look at some the ori region of Thermotoga petrophila and Vibrio cholerae."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acctaccac']\n"
     ]
    }
   ],
   "source": [
    "#Thermotoga petrophila \n",
    "frequent = FrequentWordsProblem('aactctatacctcctttttgtcgaatttgtgtgatttatagagaaaatcttattaactga'+ \\\n",
    "    'aactaaaatggtaggtttggtggtaggttttgtgtacattttgtagtatctgatttttaa' + \\\n",
    "    'ttacataccgtatattgtattaaattgacgaacaattgcatggaattgaatatatgcaaa' + \\\n",
    "    'acaaacctaccaccaaactctgtattgaccattttaggacaacttcagggtggtaggttt' + \\\n",
    "    'ctgaagctctcatcaatagactattttagtctttacaaacaatattaccgttcagattca' + \\\n",
    "    'agattctacaacgctgttttaatgggcgttgcagaaaacttaccacctaaaatccagtat' + \\\n",
    "    'ccaagccgatttcagagaaacctaccacttacctaccacttacctaccacccgggtggta' + \\\n",
    "    'agttgcagacattattaaaaacctcatcagaagcttgttcaaaaatttcaatactcgaaa' + \\\n",
    "    'cctaccacctgcgtcccctattatttactactactaataatagcagtataattgatctga', 9)\n",
    "\n",
    "print(frequent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atgatcaag', 'ctcttgatc', 'tcttgatca', 'cttgatcat']\n"
     ]
    }
   ],
   "source": [
    "#Vibrio cholerae\n",
    "frequent = FrequentWordsProblem('atcaatgatcaacgtaagcttctaagcatgatcaaggtgctcacacagtttatccacaac'+ \\\n",
    "'ctgagtggatgacatcaagataggtcgttgtatctccttcctctcgtactctcatgacca'+ \\\n",
    "'cggaaagatgatcaagagaggatgatttcttggccatatcgcaatgaatacttgtgactt'+ \\\n",
    "'gtgcttccaattgacatcttcagcgccatattgcgctggccaaggtgacggagcgggatt'+ \\\n",
    "'acgaaagcatgatcatggctgttgttctgtttatcttgttttgactgagacttgttagga'+ \\\n",
    "'tagacggtttttcatcactgactagccaaagccttactctgcctgacatcgaccgtaaat'+ \\\n",
    "'tgataatgaatttacatgcttccgcgacgatttacctcttgatcatcgatccgattgaag'+ \\\n",
    "'atcttcaattgttaattctcttgcctcgactcatagccatgatgagctcttgatcatgtt'+ \\\n",
    "'tccttaaccctctattttttacggaagaatgatcaagctgctgctcttgatcatcgtttc', 9)\n",
    "\n",
    "print(frequent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Clump Finding Problem\n",
    "\n",
    "We can define a k-mer as a \"clump\" if it appears t times within a interval L of the genome. So instead of finding clumps of a specific k-mer, let’s try to find every k-mer that forms a clump in the genome, because different genomes may use a completely different hidden messages.\n",
    "We can solve the Clump Finding Problem by applying our FrequentWords algorithm to each window of length L in Genome. If your FrequentWords implementation is not very efficient, then such an approach may be impractical. Recall that FrequentWords has O(L2 · k) running time. Applying this algorithm to each window of length L in Genome will result in an algorithm with O(L2 · k · |Genome|) running time. \n",
    "\n",
    "Firstly, let's solve the clump finding problem with our implementation of FrequentWords without frequency array. Then, let's improve our solution to FrequentWords algorithm, solve the clump finding \n",
    "problem and see the performances for both of the approaches.\n",
    "\n",
    "\n",
    "Pseudocode:\n",
    "![Pseudocode clump](data/clump.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
